{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Environment Variables and interacting with an LLM\n",
    "Let's start with the basics, first we need to make sure we are able to successfull load the environment variables from the .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from c:\\Users\\rickcau\\source\\repos\\LangGraph-101\\.env\n",
      "API Key: 8PVz****************************Isv1\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get root directory path\n",
    "root_dir = Path().absolute().parent.parent\n",
    "env_path = root_dir / '.env'\n",
    "\n",
    "# Load .env from root\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "print(f\"Loaded .env from {env_path}\")\n",
    "# Access variables\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "\n",
    "print(f\"API Key: {  api_key[:4] + '*' * 28 + api_key[-4:] }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform a very basic interaction with an LLM, in our case we will be using Azure OpenAI endpoints, so make sure you have renamed the env.example to .env and you have set all the keys to point to your Azure OpenAI instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"The sky appears blue primarily due to a phenomenon called Rayleigh scattering. When sunlight enters Earth's atmosphere, it collides with molecules and small particles in the air. Sunlight is made up of different colors, each with its own wavelength. Blue light has a shorter wavelength and is scattered in all directions more efficiently than other colors with longer wavelengths, such as red or yellow.\\n\\nDuring the day, when the Sun is high in the sky, the scattered blue light is what we predominantly see when we look up, making the sky appear blue. At sunrise and sunset, the Sun's light has to pass through a thicker layer of the atmosphere, which scatters the shorter blue wavelengths out of the direct line of sight and allows the longer red and orange wavelengths to dominate, giving the sky a reddish appearance.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 159, 'prompt_tokens': 15, 'total_tokens': 174, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-f4ece2c1-5064-4480-b209-59500904d185-0' usage_metadata={'input_tokens': 15, 'output_tokens': 159, 'total_tokens': 174, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "# Lets run a quick test\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Why is the Sky Blue?\", name=\"Rick\")\n",
    "# messages = [HumanMessage(content=f\"Why is the Sky blue?\",name=\"Rick\"))\n",
    "messages = [msg]\n",
    "\n",
    "llm = AzureChatOpenAI(model_name=\"gpt-4o\")\n",
    "result= llm.invoke(messages)\n",
    "# response = chat_model.chat(\"Hello, how can I assist you today?\")\n",
    "print(result)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great!\n",
    "You have successfully loaded your environment variables and made your first call to interact with an LLM using LangChain.  We aren't using LangGraph yet, but we first need to get through some of the basics first."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangGraph-101-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
