{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Basic Message Structure\n",
    "\n",
    "In this example, we demostrate various ways to create a messages object.  The messages object is a list.  EAch entry in the list is a dictionary that represents a message containing keys suchs as 'role' and 'content'.  \n",
    "\n",
    "For example, a typical message structure would look like this.\n",
    "\n",
    "   ~~~\n",
    "       messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in contract analysis.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Please summarize the contract.\"}\n",
    "       ]\n",
    "   ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages Object - Various Approaches\n",
    "The messages array is at the core of all Chat Completion APIs so it's very important that you undestand this.  When you leverage framrworks that interact with LLMs, often times they provide some sort of abstraction or wrapper for the raw structure.  [Here is a link](https://platform.openai.com/docs/api-reference/making-requests) to the OpenAI API reference documentation.  I highly recommend you first get familiar with how to call these endpoints by simply using CURL.\n",
    "\n",
    "Below is an example of calling an OpenAI endpoint and what is important here is the messages array structure.  All these frameworks will end up pass the messages array in this format regardless of how they abstracte the messages array, which is very important.  When you are leveraging the Messages object in LangChain or LangGraph how you interact with it may be a little different but in the end your messages arrive at the endpoint in the format below.\n",
    "\n",
    "   ~~~\n",
    "        curl https://api.openai.com/v1/chat/completions \\\n",
    "        -H \"Content-Type: application/json\" \\\n",
    "        -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
    "        -d '{\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"Say this is a test!\"}],\n",
    "            \"temperature\": 0.7\n",
    "        }'\n",
    "   ~~~\n",
    "\n",
    "I want you to keep in mind what the messages array look like above and how we create a messages object in LangChain and be mindful that in the end, when the LLM receives your messages they **WILL** be in the format above!  Let's now take a look at the different ways we can constructure our messages array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1:\n",
      "\n",
      "\n",
      "Notice in this example because we are not using the SystemMessage or HumanMessage classes so we cannot use pretty_print()\n",
      "\n",
      "{'content': 'You are an expert in contract analysis. Extract key clauses from '\n",
      "            'the provided text.',\n",
      " 'role': 'system'}\n",
      "{'content': 'This contract includes a confidentiality clause, a termination '\n",
      "            'clause, and a liability clause.',\n",
      " 'role': 'user'}\n",
      "\n",
      "Example 1a - same outcome but different approach:\n",
      "Notice how we are using the SystemMessage and HumanMessage classes to create the messages, these classes do have the pretty_print method defined.\n",
      "\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "Name: Model\n",
      "\n",
      "You are an expert in contract analysis. Extract key clauses from the provided text.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Rick\n",
      "\n",
      "This contract includes a confidentiality clause, a termination clause, and a liability clause.\n",
      "\n",
      "Example 1b same outcome but different approach:\n",
      "{'role': 'system', 'content': 'You are an expert in contract analysis. Extract key clauses from the provided text.'}\n",
      "{'role': 'user', 'content': 'This contract includes a confidentiality clause, a termination clause, and a liability clause.'}\n",
      "\n",
      "Now, let's print the messges using various ways as it's important to understand this strcuture:\n",
      "\n",
      "## pprint(messages) ##\n",
      "\n",
      "(\"[{'role': 'system', 'content': 'You are an expert in contract analysis. \"\n",
      " \"Extract key clauses from the provided text.'}, {'role': 'user', 'content': \"\n",
      " \"'This contract includes a confidentiality clause, a termination clause, and \"\n",
      " \"a liability clause.'}] \\n\")\n",
      "\n",
      "## print(messages) ##\n",
      "\n",
      "[{'role': 'system', 'content': 'You are an expert in contract analysis. Extract key clauses from the provided text.'}, {'role': 'user', 'content': 'This contract includes a confidentiality clause, a termination clause, and a liability clause.'}]\n",
      "\n",
      "## pprint(messages[0] ##\n",
      "\n",
      "{'content': 'You are an expert in contract analysis. Extract key clauses from '\n",
      "            'the provided text.',\n",
      " 'role': 'system'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from pprint import pprint\n",
    "\n",
    "# Define the system message and user message\n",
    "contract_extraction_prompt = \"You are an expert in contract analysis. Extract key clauses from the provided text.\"\n",
    "full_text = \"This contract includes a confidentiality clause, a termination clause, and a liability clause.\"\n",
    "\n",
    "# Here is an example of how to create a messages\n",
    "messages =  [\n",
    "     {\"role\": \"system\", \"content\": contract_extraction_prompt },\n",
    "     {\"role\": \"user\", \"content\": \"This contract includes a confidentiality clause, a termination clause, and a liability clause.\"}\n",
    "]\n",
    "\n",
    "# Example 1 \n",
    "print(\"\\nExample 1:\\n\")\n",
    "print(\"\\nNotice in this example because we are not using the SystemMessage or HumanMessage classes so we cannot use pretty_print()\\n\")\n",
    "for m in messages:\n",
    "    pprint(m) # We have to use the pprint to pretty print each message\n",
    "\n",
    "\n",
    "# Example 1a - same outcome, but different approach\n",
    "print(\"\\nExample 1a - same outcome but different approach:\")\n",
    "print(\"Notice how we are using the SystemMessage and HumanMessage classes to create the messages, these classes do have the pretty_print method defined.\\n\")\n",
    "messages = [SystemMessage(content=f\"You are an expert in contract analysis. Extract key clauses from the provided text.\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=full_text,name=\"Rick\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()\n",
    "\n",
    "\n",
    "# Example 1b - sample outcome, but different approach\n",
    "print(\"\\nExample 1b same outcome but different approach:\")\n",
    "messages = [{\"role\": \"system\", \"content\": contract_extraction_prompt}]\n",
    "messages.append({\"role\": \"user\", \"content\": full_text})\n",
    "\n",
    "for m in messages:\n",
    "     print(m)\n",
    "\n",
    "print(\"\\nNow, let's print the messges using various ways as it's important to understand this strcuture:\\n\")\n",
    "print(\"## pprint(messages) ##\\n\")\n",
    "pprint(f\"{messages} \\n\")\n",
    "print(\"\\n## print(messages) ##\\n\")\n",
    "print(messages)\n",
    "print(\"\\n## pprint(messages[0] ##\\n\")\n",
    "pprint(messages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Using a Message with a Custom Function Calling\n",
    "Let's start out with the most basic function calling example in-which we *DO NOT* use an Agent or a Graph.  Technically, the only thing we are using LangChain for is the AzureCahtOpenAI class and the HumanMessage and FunctionMessage wrapper objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in London is currently 22Â°C and sunny.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, FunctionMessage\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "root_dir = Path().absolute().parent\n",
    "env_path = root_dir / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Initialize the model\n",
    "model = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-4o\" # It's imporant to make sure you use the deployment name for the model you created in Azure, technically, you can call this anything!\n",
    ")\n",
    "\n",
    "# Define the function schema\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather in a location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city name\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"Temperature unit\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def get_weather(location: str, unit: str = \"celsius\") -> str:\n",
    "    \"\"\"Simulate getting weather data\"\"\"\n",
    "    return f\"It's 22Â°{'C' if unit == 'celsius' else 'F'} and sunny in {location}\"\n",
    "\n",
    "# Example conversation\n",
    "messages = [\n",
    "    HumanMessage(content=\"What's the weather like in London?\")\n",
    "]\n",
    "\n",
    "# Get the model's response with function calling\n",
    "response = model.invoke(messages, functions=functions)\n",
    "\n",
    "# Check if the model wants to call a function\n",
    "if response.additional_kwargs.get('function_call'):\n",
    "    # Get function details\n",
    "    function_call = response.additional_kwargs['function_call']\n",
    "    function_name = function_call['name']\n",
    "    function_args = json.loads(function_call['arguments'])\n",
    "    \n",
    "    # Call the function\n",
    "    function_response = get_weather(**function_args)\n",
    "    \n",
    "    # Add the function result to the messages\n",
    "    messages.append(response)\n",
    "    messages.append(FunctionMessage(\n",
    "        content=function_response,\n",
    "        name=function_name\n",
    "    ))\n",
    "    \n",
    "    # Get final response\n",
    "    final_response = model.invoke(messages)\n",
    "    print(final_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Using Prompts with Message History\n",
    "This example shows how to maintain a conversation history by appending messages to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize message history\n",
    "messages = []\n",
    "\n",
    "# Add system message\n",
    "messages.append({\"role\": \"system\", \"content\": \"You are a helpful assistant.\"})\n",
    "\n",
    "# User asks a question\n",
    "messages.append({\"role\": \"user\", \"content\": \"What are the main points of the contract?\"})\n",
    "\n",
    "# AI responds (simulated)\n",
    "ai_response = \"The main points include confidentiality, termination, and liability.\"\n",
    "\n",
    "# Append AI response to message history\n",
    "messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "\n",
    "# Continue the conversation\n",
    "messages.append({\"role\": \"user\", \"content\": \"Can you explain the confidentiality clause?\"})\n",
    "\n",
    "print(json.dumps(messages, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Using Prompt Templates\n",
    "In this example, I show you various ways to use **Prompt Templates**.  This will have you better understand the various ways you can leverage prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Example 1: Basic PromptTemplate\n",
    "basic_template = PromptTemplate.from_template(\n",
    "    \"You are a contract expert. Analyze the following text: {contract_text}\"\n",
    ")\n",
    "\n",
    "# Example 2: ChatPromptTemplate with multiple messages\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a legal expert specialized in contract analysis.\"),\n",
    "    (\"human\", \"Please analyze this contract: {contract_text}\"),\n",
    "    (\"assistant\", \"I'll analyze the contract focusing on key elements:\"),\n",
    "    (\"human\", \"Also check for any {specific_clause} clauses.\")\n",
    "])\n",
    "\n",
    "# Example 3: Template with structured formatting\n",
    "structured_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"\"\"You are a legal expert with the following responsibilities:\n",
    "    1. Analyze contract language\n",
    "    2. Identify potential risks\n",
    "    3. Suggest improvements\"\"\"),\n",
    "    HumanMessage(content=\"Contract to analyze: {contract_text}\")\n",
    "])\n",
    "\n",
    "# Sample contract text\n",
    "contract_text = \"This agreement includes confidentiality and non-compete clauses.\"\n",
    "specific_clause = \"termination\"\n",
    "\n",
    "# Format the templates\n",
    "basic_formatted = basic_template.format(contract_text=contract_text)\n",
    "chat_formatted = chat_template.format(\n",
    "    contract_text=contract_text,\n",
    "    specific_clause=specific_clause\n",
    ")\n",
    "structured_formatted = structured_template.format(\n",
    "    contract_text=contract_text\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(\"Basic Template Result:\")\n",
    "print(basic_formatted)\n",
    "print(\"\\nChat Template Result:\")\n",
    "print(chat_formatted)\n",
    "print(\"\\nStructured Template Result:\")\n",
    "print(structured_formatted)\n",
    "\n",
    "# Example of accessing individual messages from a chat template\n",
    "print(\"\\nAccessing Individual Messages from Chat Template:\")\n",
    "formatted_messages = chat_template.format_messages(\n",
    "    contract_text=contract_text,\n",
    "    specific_clause=specific_clause\n",
    ")\n",
    "for message in formatted_messages:\n",
    "    print(f\"\\n{message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5: Streaming Messages\n",
    "This is the most basic way to stream a response from the EndPoint.  Keep in mind taht we are not using LangGraph at the moment.  Our goal here is to build a strong foundation of understanding before diving deeper into LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import os, getpass\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get root directory path\n",
    "root_dir = Path().absolute().parent.parent\n",
    "env_path = root_dir / '.env'\n",
    "\n",
    "# Load .env from root\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "print(f\"Loaded .env from {env_path}\")\n",
    "# Access variables\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "\n",
    "print(f\"API Key: {  api_key[:4] + '*' * 28 + api_key[-4:] }\")\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Why is the Sky Blue?\", name=\"Rick\")\n",
    "# messages = [HumanMessage(content=f\"Why is the Sky blue?\",name=\"Rick\"))\n",
    "messages = [msg]\n",
    "\n",
    "llm = AzureChatOpenAI(model_name=\"gpt-4o\")\n",
    "for chunk in llm.stream(messages):\n",
    "    # Check if we have content to print\n",
    "    if chunk.content:\n",
    "        print(chunk.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 6: Streaming Messages using an Agent\n",
    "Ok, so let's go **right** into the deep water, very quickly.  We having even dove into the concept of State objects or Agents yet, but we will cover those topics in future models.\n",
    "\n",
    "For now, I wanted to show you a very simple example of a LangGraph Agent that makes use of a tool and one of the ways the response can be streamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from c:\\Users\\rickcau\\source\\repos\\LangGraph-101\\.env\n",
      "API Key: 8PVz****************************Isv1\n",
      "Streaming response for the detailed analysis:\n",
      "AI Messages:\n",
      "\n",
      "Tool Messages:\n",
      "Confidentiality Analysis:\n",
      "- Scope: All information shared during the project shall re...\n",
      "- Duration: Searching for time specifications...\n",
      "- Obligations: Identifying key responsibilities...\n",
      "Termination Analysis:\n",
      "- Notice Period: Searching...\n",
      "- Grounds for Termination: Analyzing conditions...\n",
      "- Post-termination obligations: Reviewing...\n",
      "Liability Analysis:\n",
      "- Limitation Scope: Total liability shall not exceed the total contrac...\n",
      "- Cap Amount: Searching for monetary limits...\n",
      "- Exclusions: Identifying carve-outs...\n",
      "AI Messages:\n",
      "Here are the detailed analyses for each of the specified contract clauses:\n",
      "\n",
      "1. **Confidentiality Clause**:\n",
      "   - **Scope**: The clause specifies that all information shared during the project is to be kept confidential. This broad scope suggests that any data, documents, or communications exchanged are protected.\n",
      "   - **Duration**: The confidentiality obligation extends for 5 years. This is a relatively standard duration, ensuring that sensitive information remains protected beyond the project's conclusion.\n",
      "   - **Obligations**: Parties involved must take reasonable measures to maintain the confidentiality of the information. This includes not disclosing it to unauthorized third parties and ensuring that any employees or agents who have access to the information are also bound by confidentiality obligations.\n",
      "   - **Potential Risks**: There is a risk of inadvertent disclosure or breach by parties who may not fully understand the extent of the confidentiality obligations. Additionally, the clause does not specify any penalties for breaches, which could complicate enforcement.\n",
      "\n",
      "2. **Termination Clause**:\n",
      "   - **Notice Period**: The clause allows either party to terminate the agreement with a 30-day notice. This provides a reasonable period for the other party to adjust to the termination and make necessary arrangements.\n",
      "   - **Grounds for Termination**: The clause is quite flexible, as it does not require specific grounds for termination. This can be advantageous if a party needs to exit the contract for unforeseen reasons but also introduces uncertainty, as termination can occur without cause.\n",
      "   - **Post-termination Obligations**: The clause does not address what happens post-termination, such as the handling of ongoing obligations or the return of confidential information, which could lead to disputes.\n",
      "\n",
      "3. **Liability Clause**:\n",
      "   - **Limitation Scope**: Liability is capped at the total contract value, which limits the financial exposure of each party. This is a common practice to prevent disproportionate liability.\n",
      "   - **Cap Amount**: The cap is directly tied to the contract value, ensuring that the maximum potential loss is predictable and manageable.\n",
      "   - **Exclusions**: The clause does not specify any exclusions or carve-outs (e.g., for gross negligence or willful misconduct), which could be a point of contention if a serious breach occurs.\n",
      "   - **Potential Risks**: While the cap protects parties from excessive liability, it might not cover all potential damages, especially in cases of significant loss or damage. It's important to ensure that the cap is sufficient relative to the potential risks involved in the project.\n",
      "\n",
      "Each clause serves to protect the parties involved, but it's crucial to ensure that all terms are clearly defined and understood to minimize legal risks and disputes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing import Type\n",
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Get root directory path\n",
    "root_dir = Path().absolute().parent.parent\n",
    "env_path = root_dir / '.env'\n",
    "\n",
    "# Load .env from root\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "print(f\"Loaded .env from {env_path}\")\n",
    "\n",
    "# Access variables\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "print(f\"API Key: {api_key[:4] + '*' * 28 + api_key[-4:]}\")\n",
    "\n",
    "# Define the input schema for our tool\n",
    "class ClauseAnalysisInput(BaseModel):\n",
    "    clause_type: str\n",
    "    clause_text: str\n",
    "\n",
    "# Create a custom tool for analyzing contract clauses\n",
    "@tool(args_schema=ClauseAnalysisInput)\n",
    "def analyze_clause(clause_type: str, clause_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes a specific contract clause and provides insights.\n",
    "    \n",
    "    Args:\n",
    "        clause_type: The type of clause (e.g., 'confidentiality', 'termination', 'liability')\n",
    "        clause_text: The actual text of the clause to analyze\n",
    "    \n",
    "    Returns:\n",
    "        str: Analysis of the clause including key points and potential risks\n",
    "    \"\"\"\n",
    "    analysis_template = {\n",
    "        'confidentiality': lambda text: f\"Confidentiality Analysis:\\n- Scope: {text[:50]}...\\n- Duration: Searching for time specifications...\\n- Obligations: Identifying key responsibilities...\",\n",
    "        'termination': lambda text: f\"Termination Analysis:\\n- Notice Period: Searching...\\n- Grounds for Termination: Analyzing conditions...\\n- Post-termination obligations: Reviewing...\",\n",
    "        'liability': lambda text: f\"Liability Analysis:\\n- Limitation Scope: {text[:50]}...\\n- Cap Amount: Searching for monetary limits...\\n- Exclusions: Identifying carve-outs...\"\n",
    "    }\n",
    "    \n",
    "    if clause_type.lower() in analysis_template:\n",
    "        return analysis_template[clause_type.lower()](clause_text)\n",
    "    return f\"Unrecognized clause type: {clause_type}. Please specify one of: confidentiality, termination, or liability.\"\n",
    "\n",
    "# Initialize the model\n",
    "model = AzureChatOpenAI(model_name=\"gpt-4o\", temperature=0.5) # Example model initialization\n",
    "\n",
    "# Add our custom tool to the tools list\n",
    "tools = [analyze_clause]\n",
    "\n",
    "# Define a dynamic system message\n",
    "def state_modifier(state):\n",
    "    return [\n",
    "        SystemMessage(content=\"\"\"You are a legal assistant specialized in contract analysis. \n",
    "        Use the analyze_clause tool to provide detailed insights about specific contract clauses.\n",
    "        Always analyze each clause type mentioned in the user's request.\"\"\"),\n",
    "        *state[\"messages\"]\n",
    "    ]\n",
    "\n",
    "# Create the agent with the state modifier and tools\n",
    "langgraph_agent_executor = create_react_agent(model, tools, state_modifier=state_modifier)\n",
    "\n",
    "# Prepare user message\n",
    "user_message = (\n",
    "    \"Please analyze the following contract clauses in detail: \"\n",
    "    \"1. Confidentiality Clause: All information shared during the project shall remain confidential for 5 years. \"\n",
    "    \"2. Termination Clause: Either party may terminate with 30 days notice. \"\n",
    "    \"3. Liability Clause: Total liability shall not exceed the total contract value. \"\n",
    "    \"For each clause, provide a detailed analysis, including implications, potential risks, and any relevant legal considerations.\"\n",
    ")\n",
    "\n",
    "# Create a HumanMessage object\n",
    "human_message = HumanMessage(content=user_message)\n",
    "\n",
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Stream the response - Sample example as earlier but using streaming\n",
    "\n",
    "# Stream the response\n",
    "print(\"Streaming response for the detailed analysis:\")\n",
    "for chunk in langgraph_agent_executor.stream({\"messages\": [human_message]}, config, stream_mode=\"updates\"):\n",
    "    # Check if the chunk contains agent messages\n",
    "    if 'agent' in chunk:\n",
    "        ai_messages = chunk['agent']['messages']\n",
    "        print(\"AI Messages:\")\n",
    "        for ai_message in ai_messages:\n",
    "            print(ai_message.content)  # Print the content of each AI message\n",
    "    # Check if the chunk contains tool messages\n",
    "    if 'tools' in chunk:\n",
    "        tool_messages = chunk['tools']['messages']\n",
    "        print(\"Tool Messages:\")\n",
    "        for tool_message in tool_messages:\n",
    "            print(tool_message.content)  # Print the content of each ToolMessage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangGraph-101-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
